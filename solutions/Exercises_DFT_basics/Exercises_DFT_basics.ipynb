{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2fe0ce8-b7ef-40d0-8d03-f85630d3ae8d",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1f53d-6a3e-4c47-afd6-f7af64c1bd20",
   "metadata": {},
   "source": [
    "This notebook contains exercises for section 2.1 of the Medford group graduate student training. These exercises cover basic DFT calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845c1165-e92b-49ee-a8b1-acfed1ad01d1",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33441ff2",
   "metadata": {},
   "source": [
    "We begin with single point calculations in SPARC. Compute gas-phase formation energies for water, carbon dioxide, and ammonia using the common Perdew–Burke-Ernzerhof generalized gradient approximation (GGA) functional. You can get the reference energy for carbon from graphite. Compare your results to those from experimentation. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3d2476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hice1/nyu49/Data/VIP/Excercises/Exercises_DFT_basics/Exercise_1/PBE/H2O already exists.\n",
      "/home/hice1/nyu49/Data/VIP/Excercises/Exercises_DFT_basics/Exercise_1/PBE/CO2 already exists.\n",
      "/home/hice1/nyu49/Data/VIP/Excercises/Exercises_DFT_basics/Exercise_1/PBE/NH3 already exists.\n",
      "/home/hice1/nyu49/Data/VIP/Excercises/Exercises_DFT_basics/Exercise_1/PBE/H2 already exists.\n",
      "/home/hice1/nyu49/Data/VIP/Excercises/Exercises_DFT_basics/Exercise_1/PBE/O2 already exists.\n",
      "/home/hice1/nyu49/Data/VIP/Excercises/Exercises_DFT_basics/Exercise_1/PBE/N2 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/nyu49/.local/lib/python3.9/site-packages/sparc/calculator.py:471: UserWarning: You have specified one of FD_GRID, ECUT or MESH_SPACING, conversion of h to mesh grid is ignored.\n",
      "  warn(\"You have specified one of FD_GRID, ECUT or MESH_SPACING, \"\n",
      "srun: Job 11957 step creation temporarily disabled, retrying (Requested nodes are busy)\n",
      "srun: Step created for job 11957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  0\n",
      "Step  1\n",
      "Step  2\n",
      "{}\n",
      "[0, 1, 2, 3] [0, 1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/nyu49/.local/lib/python3.9/site-packages/sparc/sparc_parsers/utils.py:56: UserWarning: Key POISSON_SOLVER not in validator's parameter list, ignore value conversion!\n",
      "  warn(\n",
      "/home/hice1/nyu49/.local/lib/python3.9/site-packages/sparc/sparc_parsers/utils.py:56: UserWarning: Key VERBOSITY not in validator's parameter list, ignore value conversion!\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ase import Atoms, io\n",
    "from ase.io import read, write\n",
    "from ase.build import bulk, molecule, surface, add_adsorbate\n",
    "from ase.units import Bohr,Hartree,mol,kcal,kJ,eV\n",
    "from sparc import SPARC\n",
    "\n",
    "cwd = os.getcwd()\n",
    "E_dict = {}\n",
    "\n",
    "mol_list = ['H2O', 'CO2', 'NH3', 'H2', 'O2', 'N2', 'graphite']\n",
    "for mol in mol_list:\n",
    "    \n",
    "    if mol not in ['graphite']:\n",
    "        atoms = molecule(mol)\n",
    "        atoms.cell = [[10,0,0],[0,10,0],[0,0,10]]\n",
    "        atoms.pbc = True\n",
    "\n",
    "    parameters = dict(\n",
    "                    EXCHANGE_CORRELATION = 'GGA_PBE',\n",
    "                    D3_FLAG=1,   #Grimme D3 dispersion correction\n",
    "                    SPIN_TYP=1,   #spin-polarized calculation\n",
    "                    KPOINT_GRID=[1,1,1],  \n",
    "                    ECUT=800/Hartree,   #set ECUT (Hartree) or h (Angstrom)\n",
    "                    #h = 0.15,\n",
    "                    TOL_SCF=1e-4,\n",
    "                    RELAX_FLAG=1,\n",
    "                    TOL_RELAX = 5.00E-04,  #convergence criteria (maximum force) (Ha/Bohr)\n",
    "                    PRINT_FORCES=1,\n",
    "                    PRINT_RELAXOUT=1)\n",
    "    \n",
    "    dir_i = f\"{cwd}/Exercise_1/PBE/{mol}\"\n",
    "    parameters['directory'] = dir_i\n",
    "    \n",
    "    if os.path.isdir(dir_i):\n",
    "        print(f\"{dir_i} already exists.\")\n",
    "        continue\n",
    "    \n",
    "    if mol == 'H2':\n",
    "        parameters['SPIN_TYP']=0\n",
    "    elif mol == 'graphite':\n",
    "        atoms = read('graphite.cif')\n",
    "        parameters['KPOINT_GRID'] = [6,6,2]\n",
    "    \n",
    "    calc = SPARC(atoms = atoms, **parameters)\n",
    "    atoms.set_calculator(calc)\n",
    "\n",
    "    eng = atoms.get_potential_energy()\n",
    "    E_dict[mol] = eng\n",
    "    \n",
    "    with open(f'{dir_i}/energy.txt', 'w') as f:\n",
    "        f.write(str(eng))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bfc87273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "def readFile(path):\n",
    "    f = open(path, 'r')\n",
    "    content = f.readlines()\n",
    "    return content\n",
    "\n",
    "def read_energy(path):\n",
    "    energy = float(readFile(path)[0])\n",
    "    return energy\n",
    "\n",
    "def get_E_form(name):\n",
    "    E_elem = {}\n",
    "    E_elem['H'] = E_dict['H2']/2\n",
    "    E_elem['O'] = E_dict['O2']/2\n",
    "    E_elem['C'] = E_dict['graphite'] / len(read('graphite.cif'))\n",
    "    E_elem['N'] = E_dict['N2']/2\n",
    "    counts = mol_dict[name].symbols.formula.count()    \n",
    "    E_form = E_dict[name]\n",
    "    \n",
    "    #print(counts, E_form)\n",
    "    for elem in counts:\n",
    "        #print(counts[elem], E_elem[elem])\n",
    "        E_form += -counts[elem] * E_elem[elem]\n",
    "    return E_form \n",
    "\n",
    "E_dict, mol_dict, t_dict = {}, {}, {}\n",
    "for mol in mol_list:\n",
    "    \n",
    "     ### get energy dictionary\n",
    "    dir_mol = f'Exercise_1/PBE/{mol}'\n",
    "    E_dict[mol] = read_energy(f'{dir_mol}/energy.txt')\n",
    "    \n",
    "     ### get Atoms dictionary\n",
    "    try:\n",
    "        mol_dict[mol] = molecule(mol)    \n",
    "    except KeyError:\n",
    "        pass\n",
    "    mol_dict['graphite'] = read('graphite.cif')\n",
    "    \n",
    "     ### get time dictionary\n",
    "    sparc_out = os.path.join(dir_mol, 'SPARC.out')\n",
    "    with open(sparc_out, 'r') as f: data = f.read()\n",
    "    t_SPARC = float(re.search(r'Total walltime\\s+:\\s+([0-9.]+)', data).group(1)) \n",
    "    t_SPARC = float(f\"{t_SPARC:.3f}\")\n",
    "    t_dict[mol] = t_SPARC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "614d8a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ΔE_form (H2O). Calculation: -2.518 eV (8.542 sec to calculate H2O)\n",
      "\t        Experiment: -2.713\n",
      "ΔE_form (CO2). Calculation: -3.903 eV (16.004 sec to calculate CO2)\n",
      "\t        Experiment: -4.128\n",
      "ΔE_form (NH3). Calculation: -1.061 eV (10.887 sec to calculate NH3)\n",
      "\t        Experiment: -0.816\n"
     ]
    }
   ],
   "source": [
    "E_form_dict_Expt = json.load(open('E_form_dict_Expt.json', 'r'))\n",
    "\n",
    "for mol in mol_list:\n",
    "    E_form = get_E_form(mol)\n",
    "    if E_form != 0:\n",
    "        print(f\"\\u0394E_form ({mol}). Calculation: {E_form:.3f} eV ({t_dict[mol]} sec to calculate {mol})\")\n",
    "        print(f\"\\t        Experiment: {E_form_dict_Expt[mol]:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4ec58",
   "metadata": {},
   "source": [
    "Repeat the above calculations using the B3LYP hydrid functional. How do these energies compare to those from experimentation and from DFT with the PBE functional? Does the computation time with the B3LYP change? Explain why or why not.\n",
    " # # Not completed due to sparc-dft-api error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d13501cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  0\n",
      "Step  1\n",
      "Step  2\n",
      "Step  3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m calc \u001b[38;5;241m=\u001b[39m SPARC(atoms \u001b[38;5;241m=\u001b[39m atoms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[1;32m     45\u001b[0m atoms\u001b[38;5;241m.\u001b[39mset_calculator(calc)\n\u001b[0;32m---> 47\u001b[0m eng \u001b[38;5;241m=\u001b[39m \u001b[43matoms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_potential_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m E_dict[mol] \u001b[38;5;241m=\u001b[39m eng\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/energy.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ase/atoms.py:731\u001b[0m, in \u001b[0;36mAtoms.get_potential_energy\u001b[0;34m(self, force_consistent, apply_constraint)\u001b[0m\n\u001b[1;32m    728\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc\u001b[38;5;241m.\u001b[39mget_potential_energy(\n\u001b[1;32m    729\u001b[0m         \u001b[38;5;28mself\u001b[39m, force_consistent\u001b[38;5;241m=\u001b[39mforce_consistent)\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 731\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_potential_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_constraint:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m constraint \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraints:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ase/calculators/calculator.py:709\u001b[0m, in \u001b[0;36mCalculator.get_potential_energy\u001b[0;34m(self, atoms, force_consistent)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_potential_energy\u001b[39m(\u001b[38;5;28mself\u001b[39m, atoms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_consistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 709\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_property\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menergy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matoms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_consistent:\n\u001b[1;32m    711\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfree_energy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ase/calculators/calculator.py:737\u001b[0m, in \u001b[0;36mCalculator.get_property\u001b[0;34m(self, name, atoms, allow_calculation)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_calculation:\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43matoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_changes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# For some reason the calculator was not able to do what we want,\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;66;03m# and that is OK.\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PropertyNotImplementedError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not present in this \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    743\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalculation\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/calculator.py:201\u001b[0m, in \u001b[0;36mSPARC.calculate\u001b[0;34m(self, atoms, properties, system_changes)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_input(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matoms, properties, system_changes)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Extra step, copy the atoms back to original atoms, if it's an\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# geopt or aimd calculation\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeopt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_results) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maimd\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_results):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# Update the parent atoms\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/calculator.py:369\u001b[0m, in \u001b[0;36mSPARC.read_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"Parse from the SparcBundle\"\"\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# TODO: try use cache?\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# self.sparc_bundle.read_raw_results()\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparc_bundle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_ase\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_all_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    371\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matoms \u001b[38;5;241m=\u001b[39m last\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mupdate(last\u001b[38;5;241m.\u001b[39mcalc\u001b[38;5;241m.\u001b[39mresults)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/io.py:356\u001b[0m, in \u001b[0;36mSparcBundle.convert_to_ase\u001b[0;34m(self, index, include_all_files, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"Read the raw results from the bundle and create atoms with\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03msingle point calculators\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03mTODO: what to do about the indices?\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# Convert to images!\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_raw_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_all_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_all_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    358\u001b[0m     raw_results \u001b[38;5;241m=\u001b[39m [rs]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/io.py:290\u001b[0m, in \u001b[0;36mSparcBundle.read_raw_results\u001b[0;34m(self, include_all_files)\u001b[0m\n\u001b[1;32m    285\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_results_from_index(index)\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_calculations)\n\u001b[1;32m    288\u001b[0m     ]\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_results_from_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_results \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_all_files:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/io.py:323\u001b[0m, in \u001b[0;36mSparcBundle._read_results_from_index\u001b[0;34m(self, index, d_format)\u001b[0m\n\u001b[1;32m    321\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indir(ext, occur\u001b[38;5;241m=\u001b[39mindex, d_format\u001b[38;5;241m=\u001b[39md_format)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m--> 323\u001b[0m         data_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_read_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m         results_dict\u001b[38;5;241m.\u001b[39mupdate(data_dict)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Must have files: ion, inpt\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# TODO: make another function to check sanity\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ase/utils/__init__.py:486\u001b[0m, in \u001b[0;36miofunction.__call__.<locals>.iofunc\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         fd \u001b[38;5;241m=\u001b[39m file\n\u001b[0;32m--> 486\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/sparc_parsers/out.py:50\u001b[0m, in \u001b[0;36m_read_out\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m     47\u001b[0m output_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _read_run_info(contents)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# List of scf information,\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# including scf convergence, energy etc\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m output_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mionic_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_read_scfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_dict}\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/sparc_parsers/out.py:148\u001b[0m, in \u001b[0;36m_read_scfs\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m    145\u001b[0m conv_header \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m3,}\u001b[39m\u001b[38;5;124m\"\u001b[39m, conv_lines[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# In some cases the ionic step ends with a warning message\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# To be flexible, we only extract lines starting with a number\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m conv_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt([l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m conv_lines \u001b[38;5;28;01mif\u001b[39;00m l\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39misdigit()], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# TODO: the meaning of the header should me split to the width\u001b[39;00m\n\u001b[1;32m    151\u001b[0m conv_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sparc/sparc_parsers/out.py:148\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    145\u001b[0m conv_header \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m3,}\u001b[39m\u001b[38;5;124m\"\u001b[39m, conv_lines[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# In some cases the ionic step ends with a warning message\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# To be flexible, we only extract lines starting with a number\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m conv_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt([l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m conv_lines \u001b[38;5;28;01mif\u001b[39;00m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misdigit()], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# TODO: the meaning of the header should me split to the width\u001b[39;00m\n\u001b[1;32m    151\u001b[0m conv_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ase import Atoms, io\n",
    "from ase.io import read, write\n",
    "from ase.build import bulk, molecule, surface, add_adsorbate\n",
    "from ase.units import Bohr,Hartree,mol,kcal,kJ,eV\n",
    "from sparc import SPARC\n",
    "\n",
    "cwd = os.getcwd()\n",
    "E_dict = {}\n",
    "\n",
    "mol_list = ['H2O', 'CO2', 'NH3', 'H2', 'O2', 'N2', 'graphite']\n",
    "for mol in mol_list:\n",
    "    \n",
    "    if mol not in ['graphite']:\n",
    "        atoms = molecule(mol)\n",
    "        atoms.cell = [[10,0,0],[0,10,0],[0,0,10]]\n",
    "        atoms.pbc = True\n",
    "\n",
    "    parameters = dict(\n",
    "                    EXCHANGE_CORRELATION = 'PBE0',\n",
    "                    D3_FLAG=1,   #Grimme D3 dispersion correction\n",
    "                    SPIN_TYP=1,   #spin-polarized calculation\n",
    "                    KPOINT_GRID=[1,1,1],  \n",
    "                    ECUT=800/Hartree,   #set ECUT (Hartree) or h (Angstrom)\n",
    "                    #h = 0.15,\n",
    "                    TOL_SCF=1e-4,\n",
    "                    RELAX_FLAG=1,\n",
    "                    TOL_RELAX = 5.00E-04,  #convergence criteria (maximum force) (Ha/Bohr)\n",
    "                    PRINT_FORCES=1,\n",
    "                    PRINT_RELAXOUT=1)\n",
    "    \n",
    "    dir_i = f\"{cwd}/Exercise_1/PBE0/{mol}\"\n",
    "    parameters['directory'] = dir_i\n",
    "    \n",
    "    if os.path.isdir(dir_i):\n",
    "        print(f\"{dir_i} already exists.\")\n",
    "        continue\n",
    "    \n",
    "    if mol == 'H2':\n",
    "        parameters['SPIN_TYP']=0\n",
    "    elif mol == 'graphite':\n",
    "        atoms = read('graphite.cif')\n",
    "    \n",
    "    calc = SPARC(atoms = atoms, **parameters)\n",
    "    atoms.set_calculator(calc)\n",
    "\n",
    "    eng = atoms.get_potential_energy()\n",
    "    E_dict[mol] = eng\n",
    "    \n",
    "    with open(f'{dir_i}/energy.txt', 'w') as f:\n",
    "        f.write(str(eng))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d656717",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54072710",
   "metadata": {},
   "source": [
    "Next, we revisit Ca-LTA from the prior ASE exercises. Use DFT with the PBE functional to perform a single point energy calculation for the empty Ca-LTA framework. Report the resulting energy in eV/atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fb3b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "[73, 55, 56, 57, 58, 59, 60, 61, 54, 62, 72, 64, 65, 66, 67, 68, 63, 69, 70, 71, 3, 0, 1, 2, 42, 47, 43, 44, 45, 46, 53, 48, 49, 50, 51, 52, 39, 40, 41, 38, 18, 16, 15, 14, 13, 12, 11, 17, 10, 9, 8, 7, 6, 19, 28, 20, 36, 35, 34, 33, 32, 31, 30, 37, 29, 27, 26, 25, 24, 23, 22, 21, 5, 4] [21, 22, 23, 20, 73, 72, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 47, 40, 53, 55, 71, 70, 69, 68, 67, 66, 65, 54, 64, 62, 61, 60, 59, 58, 57, 56, 63, 39, 36, 37, 38, 24, 26, 27, 28, 29, 25, 31, 32, 33, 34, 35, 30, 8, 1, 2, 3, 4, 5, 6, 7, 9, 16, 11, 12, 13, 14, 15, 17, 18, 19, 10, 0]\n",
      "NoD3_NoSpin: -26353.786194078464\n",
      "{}\n",
      "[73, 55, 56, 57, 58, 59, 60, 61, 54, 62, 72, 64, 65, 66, 67, 68, 63, 69, 70, 71, 3, 0, 1, 2, 42, 47, 43, 44, 45, 46, 53, 48, 49, 50, 51, 52, 39, 40, 41, 38, 18, 16, 15, 14, 13, 12, 11, 17, 10, 9, 8, 7, 6, 19, 28, 20, 36, 35, 34, 33, 32, 31, 30, 37, 29, 27, 26, 25, 24, 23, 22, 21, 5, 4] [21, 22, 23, 20, 73, 72, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 47, 40, 53, 55, 71, 70, 69, 68, 67, 66, 65, 54, 64, 62, 61, 60, 59, 58, 57, 56, 63, 39, 36, 37, 38, 24, 26, 27, 28, 29, 25, 31, 32, 33, 34, 35, 30, 8, 1, 2, 3, 4, 5, 6, 7, 9, 16, 11, 12, 13, 14, 15, 17, 18, 19, 10, 0]\n",
      "D3_NoSpin: -26357.73922193604\n",
      "{}\n",
      "[73, 55, 56, 57, 58, 59, 60, 61, 54, 62, 72, 64, 65, 66, 67, 68, 63, 69, 70, 71, 3, 0, 1, 2, 42, 47, 43, 44, 45, 46, 53, 48, 49, 50, 51, 52, 39, 40, 41, 38, 18, 16, 15, 14, 13, 12, 11, 17, 10, 9, 8, 7, 6, 19, 28, 20, 36, 35, 34, 33, 32, 31, 30, 37, 29, 27, 26, 25, 24, 23, 22, 21, 5, 4] [21, 22, 23, 20, 73, 72, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 47, 40, 53, 55, 71, 70, 69, 68, 67, 66, 65, 54, 64, 62, 61, 60, 59, 58, 57, 56, 63, 39, 36, 37, 38, 24, 26, 27, 28, 29, 25, 31, 32, 33, 34, 35, 30, 8, 1, 2, 3, 4, 5, 6, 7, 9, 16, 11, 12, 13, 14, 15, 17, 18, 19, 10, 0]\n",
      "D3_Spin: -26357.742824245048\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ase import Atoms, io\n",
    "from ase.io import read, write\n",
    "from ase.build import bulk, molecule, surface, add_adsorbate\n",
    "from ase.units import Bohr,Hartree,mol,kcal,kJ,eV\n",
    "from sparc import SPARC\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "for setting in ['NoD3_NoSpin', 'D3_NoSpin', 'D3_Spin']:\n",
    "\n",
    "    parameters = dict(\n",
    "                    EXCHANGE_CORRELATION = 'GGA_PBE',\n",
    "                    D3_FLAG=0,   #Grimme D3 dispersion correction\n",
    "                    SPIN_TYP=0,   #spin-polarized calculation\n",
    "                    KPOINT_GRID=[1,1,1],  \n",
    "                    ECUT=600/Hartree,   #set ECUT (Hartree) or h (Angstrom)\n",
    "                    #h = 0.15,\n",
    "                    TOL_SCF=1e-4,\n",
    "                    RELAX_FLAG=0,\n",
    "                    TOL_RELAX = 5.00E-04,  #convergence criteria (maximum force) (Ha/Bohr)\n",
    "                    PRINT_FORCES=1,\n",
    "                    PRINT_RELAXOUT=1)\n",
    "    \n",
    "    dir_i = f\"{cwd}/Exercise_2/{setting}\"\n",
    "    parameters['directory'] = dir_i\n",
    "    \n",
    "    if setting == 'NoD3_NoSpin':\n",
    "        parameters['D3_FLAG'] = 0\n",
    "        parameters['SPIN_TYP'] = 0 \n",
    "    elif setting == 'D3_NoSpin':\n",
    "        parameters['D3_FLAG'] = 1 \n",
    "        parameters['SPIN_TYP'] = 0 \n",
    "    elif setting == 'D3_Spin':\n",
    "        parameters['D3_FLAG'] = 1 \n",
    "        parameters['SPIN_TYP'] = 1 \n",
    "        \n",
    "    if os.path.isdir(dir_i):\n",
    "        print(f\"{dir_i} already exists.\")\n",
    "        continue\n",
    "    \n",
    "    atoms = read('CaLTA.vasp')\n",
    "    atoms.pbc = True\n",
    "    \n",
    "    calc = SPARC(atoms = atoms, **parameters)\n",
    "    atoms.set_calculator(calc)\n",
    "\n",
    "    eng = atoms.get_potential_energy()\n",
    "    print(f\"{setting}: {eng}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8baba6",
   "metadata": {},
   "source": [
    "Repeat the above calculation with both spin polarization and a D3 dispersion correction with Becke-Johnson damping. How does the answer change and why?\n",
    "# # NO D3-BJ in SPARC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b00db54",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0715a00",
   "metadata": {},
   "source": [
    "Follow the steps from the previous set of exercises to import Ca-LTA as an Atoms object with periodic boundary conditions. But this time, use LiH5C5N2O5 structure for faster calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "384bd9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "from ase import Atoms, io\n",
    "from ase.io import read, write\n",
    "\n",
    "atoms = read('LiH5C5N2O5.cif')\n",
    "atoms.pbc = True\n",
    "\n",
    "print(len(atoms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4975fba",
   "metadata": {},
   "source": [
    "Use an ASE calculator to compute the potential energy (Do single-point calculation, which means that you don't need to do atomic relaxation) for LiH5C5N2O5 in eV/atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff0bf826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "srun: Job 11957 step creation temporarily disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Job 11957 step creation still disabled, retrying (Requested nodes are busy)\n",
      "srun: Step created for job 11957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "[10, 5, 6, 7, 8, 9, 1, 2, 0, 4, 3, 11, 12, 13, 14, 15, 16, 17] [8, 6, 7, 10, 9, 1, 2, 3, 4, 5, 0, 11, 12, 13, 14, 15, 16, 17]\n",
      "-3911.4133248926873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/nyu49/.local/lib/python3.9/site-packages/sparc/sparc_parsers/out.py:108: UserWarning: Key atomic mass from run information appears multiple times in your outputfile!\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sparc import SPARC\n",
    "from ase.units import Bohr,Hartree,mol,kcal,kJ,eV\n",
    "\n",
    "parameters = dict(\n",
    "                EXCHANGE_CORRELATION = 'GGA_PBE',\n",
    "                D3_FLAG=1,   #Grimme D3 dispersion correction\n",
    "                SPIN_TYP=0,   #non spin-polarized calculation\n",
    "                KPOINT_GRID=[2,2,1],  #slab needs only 1 kpt in z-direction \n",
    "                ECUT=500/Hartree,   #set ECUT (Hartree) or h (Angstrom)\n",
    "                #h = 0.15,\n",
    "                TOL_SCF=1e-4,\n",
    "                RELAX_FLAG=0,\n",
    "                TOL_RELAX = 3.00E-03,  #convergence criteria (maximum force) (Ha/Bohr)\n",
    "                PRINT_FORCES=1,\n",
    "                PRINT_RELAXOUT=1)\n",
    "\n",
    "parameters['directory'] = 'Exercise_3'\n",
    "\n",
    "calc = SPARC(atoms = atoms, **parameters)\n",
    "atoms.set_calculator(calc)\n",
    "\n",
    "eng = atoms.get_potential_energy()\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6b888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae56723e",
   "metadata": {},
   "source": [
    "Next, manipulate the ASE Atoms object by increasing each cell lattice parameter by 20%. Be sure to scale atomic positions when setting the cell parameters. Visualize the expanded unit cell using ASE tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76131adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell0 = atoms.get_cell()\n",
    "\n",
    "atoms2 = atoms.copy()\n",
    "atoms2.set_cell(cell0*1.2, scale_atoms=True)  \n",
    "print('original:', cell0.lengths())\n",
    "print('new:', atoms2.get_cell().lengths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2cc7ab",
   "metadata": {},
   "source": [
    "Perform full optimization (both atomic positions and cell) in ASE starting from the expanded unit cell. Use the BFGS algorithm and print the trajectory to \"opt.traj\". Confirm that the lattice parameters relax to approximately the values from the original structure.\n",
    "\n",
    "### # Currently, ase optimizers do not work well with sparc-dft-api.\n",
    "### # So, this solution doesn't create \"opt.traj.\"\n",
    "### # There is an error with RELAX_FLAG=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms3 = atoms2.copy()\n",
    "\n",
    "parameters['RELAX_FLAG'] = 2\n",
    "#calc = SPARC(atoms = atoms3, **parameters)\n",
    "calc = EMT()\n",
    "\n",
    "atoms3.set_calculator(calc)\n",
    "\n",
    "eng = atoms3.get_potential_energy()\n",
    "print(eng)\n",
    "print(atoms3.get_cell().lengths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459afc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
