{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2fe0ce8-b7ef-40d0-8d03-f85630d3ae8d",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1f53d-6a3e-4c47-afd6-f7af64c1bd20",
   "metadata": {},
   "source": [
    "This notebook contains exercises for section 3.2 of the Medford group graduate student training. These exercises cover basic ML strategies, including classification and generative models. <br><br>\n",
    "**NOTE:** These exercises cover only a small sample of ML techniques. All ML will be implemented in the *scikit-learn* Python package here. Documentation can be found at https://scikit-learn.org/stable/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845c1165-e92b-49ee-a8b1-acfed1ad01d1",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33441ff2",
   "metadata": {},
   "source": [
    "This exercise will use Supper Vector Machines to build a classification model for a 2-class dataset with a dimensionality of 2. Begin by creating a moons toy dataset with 200 samples and a noise of 0.1 using the sklearn.datasets.make_moons function: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html<br><br>\n",
    "Visualize the dataset and color each point according to its assigned class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d2476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0c4ba",
   "metadata": {},
   "source": [
    "Train a support vector machine with a radial basis function (RBF) kernel to create a discriminative classification model for this dataset. Tune the *gamma* and *C* parameters to achieve a minimum accuracy of 90%.<br><br> Comment on what happens as *C* goes to 0 and as *C* goes to infinity.\n",
    "Plot the data colored by class and show the SVM decision boundary. Calculate the accuracy, precision, and recall for your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ecc3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06276c",
   "metadata": {},
   "source": [
    "Show the confusion matrix for your best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84409be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d656717",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54072710",
   "metadata": {},
   "source": [
    "This exercise is a continuation of the previous and uses the same dataset. <br><br>\n",
    "Create an random 80/20 train/test split for the moons dataset from above. For k in [2,5,10,20], use a k-nearest neighbors (kNN) model for classification. Use subplots to show the result with each point colored according to its predicted class for each value of k. Compute the accuracy for each case. <br><br>Laslty, explain what the loss function is for a kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623f090",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8424ed9",
   "metadata": {},
   "source": [
    "This exercise will focus on multi-class classification. Use the sklearn make_blobs function to generate a toy dataset with 150 samples, 4 clusters, and a dimensionality of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cbbe3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd8616",
   "metadata": {},
   "source": [
    "Next, use PCA to reduce the dimensionality to 2. Plot the dataset with each point colored according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96ddddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d1c5a",
   "metadata": {},
   "source": [
    "Train a decision tree model (discriminative) model on the reduced dataset and plot the result with points colored according to their predicted class. Be sure to perform hyperparameter tuning as necessary; you can decide the extent to which this is necessary. Compute the accuracy, precision, and recall scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f07b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d515404",
   "metadata": {},
   "source": [
    "Repeat the above task with a naive Gaussian model (generative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee978a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328ad60",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a54db",
   "metadata": {},
   "source": [
    "This exercise focuses on unsupervised generative models, which can be used to generate new data based on patterns learned from existing data. Begin by importing the digits dataset from sklearn (also called the MNIST dataset). This is a high-dimensionality dataset consisting of hand-drawn digits (0â€“9) commonly used for training image processing systems. It consists of 1,797 samples, each corresponding to one of the ten digits. Each sample can be presented by an 8 x 8 grid of pixels, where each pixel is colored according to its corresponding hand-drawn image. Thus, the dimensionality is 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bee71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13980e37",
   "metadata": {},
   "source": [
    "Create a Gaussian mixture model (GMM) to create three new examples of the digit 6. You can use the y_mnist variable to quickly select this subset (y_mnist == 6). Show each of your predictions. Use spherical covariance and toy with the number of mixture components to create a model that can generative reasonably convincing synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f674d50",
   "metadata": {},
   "source": [
    "Create a kernel density estimation (KDE) model to create three new examples of the digit 6. Show each of your predictions. Use a Gaussian kernel and toy with the bandwidth to create a model that can generative reasonably convincing synthetic data. Compare the KDE model to the GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed043605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29ecd9",
   "metadata": {},
   "source": [
    "Create three synthetic examples of the digit 2 using a generative model of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
